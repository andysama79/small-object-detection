{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from backbone import Backbone\n",
    "from neck import Neck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/schecter/miniconda3/envs/pikachu/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "back_model = Backbone(hid_dim=96, layers=(2, 2, 2, 2), heads=(3, 6, 12, 24))\n",
    "# back_out, feature_maps = back_model(torch.randn(1, 3, 1024, 1024))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "back_out.shape, [f.shape for f in feature_maps]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "neck_model = Neck(hid_dim=96, layers=(2, 2, 2, 2), heads=(3, 6, 12, 24), channels=768)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neck_out = neck_model(back_out.permute(0, 3, 1, 2), feature_maps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neck_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import Model\n",
    "from head import Head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "head_model = Head(in_channels=96, num_classes=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = Model(back_model, neck_model, head_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([1, 32, 32, 768]), Feature map shape: torch.Size([1, 32, 32, 768])\n",
      "features:  torch.Size([1, 256, 256, 96])\n",
      "torch.Size([1, 96, 256, 256])\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "mod_out = mod(torch.randn(1, 3, 1024, 1024))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------------------------------------+------------+\n",
      "|                           Modules                           | Parameters |\n",
      "+-------------------------------------------------------------+------------+\n",
      "|       model.stage1.patch_partition.patch_merge.weight       |    4608    |\n",
      "|        model.stage1.patch_partition.patch_merge.bias        |     96     |\n",
      "|    model.stage1.layers.0.0.attention_block.fn.norm.weight   |     96     |\n",
      "|     model.stage1.layers.0.0.attention_block.fn.norm.bias    |     96     |\n",
      "|    model.stage1.layers.0.0.attention_block.fn.fn.pos_emb    |     9      |\n",
      "|      model.stage1.layers.0.0.attention_block.fn.fn.tau      |     1      |\n",
      "| model.stage1.layers.0.0.attention_block.fn.fn.to_qkv.weight |   27648    |\n",
      "| model.stage1.layers.0.0.attention_block.fn.fn.to_out.weight |    9216    |\n",
      "|  model.stage1.layers.0.0.attention_block.fn.fn.to_out.bias  |     96     |\n",
      "|       model.stage1.layers.0.0.mlp_block.fn.norm.weight      |     96     |\n",
      "|        model.stage1.layers.0.0.mlp_block.fn.norm.bias       |     96     |\n",
      "|   model.stage1.layers.0.0.mlp_block.fn.fn.network.0.weight  |   36864    |\n",
      "|    model.stage1.layers.0.0.mlp_block.fn.fn.network.0.bias   |    384     |\n",
      "|   model.stage1.layers.0.0.mlp_block.fn.fn.network.2.weight  |   36864    |\n",
      "|    model.stage1.layers.0.0.mlp_block.fn.fn.network.2.bias   |     96     |\n",
      "|    model.stage1.layers.0.1.attention_block.fn.norm.weight   |     96     |\n",
      "|     model.stage1.layers.0.1.attention_block.fn.norm.bias    |     96     |\n",
      "|    model.stage1.layers.0.1.attention_block.fn.fn.pos_emb    |     9      |\n",
      "|      model.stage1.layers.0.1.attention_block.fn.fn.tau      |     1      |\n",
      "| model.stage1.layers.0.1.attention_block.fn.fn.to_qkv.weight |   27648    |\n",
      "| model.stage1.layers.0.1.attention_block.fn.fn.to_out.weight |    9216    |\n",
      "|  model.stage1.layers.0.1.attention_block.fn.fn.to_out.bias  |     96     |\n",
      "|       model.stage1.layers.0.1.mlp_block.fn.norm.weight      |     96     |\n",
      "|        model.stage1.layers.0.1.mlp_block.fn.norm.bias       |     96     |\n",
      "|   model.stage1.layers.0.1.mlp_block.fn.fn.network.0.weight  |   36864    |\n",
      "|    model.stage1.layers.0.1.mlp_block.fn.fn.network.0.bias   |    384     |\n",
      "|   model.stage1.layers.0.1.mlp_block.fn.fn.network.2.weight  |   36864    |\n",
      "|    model.stage1.layers.0.1.mlp_block.fn.fn.network.2.bias   |     96     |\n",
      "|       model.stage2.patch_partition.patch_merge.weight       |   73728    |\n",
      "|        model.stage2.patch_partition.patch_merge.bias        |    192     |\n",
      "|    model.stage2.layers.0.0.attention_block.fn.norm.weight   |    192     |\n",
      "|     model.stage2.layers.0.0.attention_block.fn.norm.bias    |    192     |\n",
      "|    model.stage2.layers.0.0.attention_block.fn.fn.pos_emb    |     9      |\n",
      "|      model.stage2.layers.0.0.attention_block.fn.fn.tau      |     1      |\n",
      "| model.stage2.layers.0.0.attention_block.fn.fn.to_qkv.weight |   110592   |\n",
      "| model.stage2.layers.0.0.attention_block.fn.fn.to_out.weight |   36864    |\n",
      "|  model.stage2.layers.0.0.attention_block.fn.fn.to_out.bias  |    192     |\n",
      "|       model.stage2.layers.0.0.mlp_block.fn.norm.weight      |    192     |\n",
      "|        model.stage2.layers.0.0.mlp_block.fn.norm.bias       |    192     |\n",
      "|   model.stage2.layers.0.0.mlp_block.fn.fn.network.0.weight  |   147456   |\n",
      "|    model.stage2.layers.0.0.mlp_block.fn.fn.network.0.bias   |    768     |\n",
      "|   model.stage2.layers.0.0.mlp_block.fn.fn.network.2.weight  |   147456   |\n",
      "|    model.stage2.layers.0.0.mlp_block.fn.fn.network.2.bias   |    192     |\n",
      "|    model.stage2.layers.0.1.attention_block.fn.norm.weight   |    192     |\n",
      "|     model.stage2.layers.0.1.attention_block.fn.norm.bias    |    192     |\n",
      "|    model.stage2.layers.0.1.attention_block.fn.fn.pos_emb    |     9      |\n",
      "|      model.stage2.layers.0.1.attention_block.fn.fn.tau      |     1      |\n",
      "| model.stage2.layers.0.1.attention_block.fn.fn.to_qkv.weight |   110592   |\n",
      "| model.stage2.layers.0.1.attention_block.fn.fn.to_out.weight |   36864    |\n",
      "|  model.stage2.layers.0.1.attention_block.fn.fn.to_out.bias  |    192     |\n",
      "|       model.stage2.layers.0.1.mlp_block.fn.norm.weight      |    192     |\n",
      "|        model.stage2.layers.0.1.mlp_block.fn.norm.bias       |    192     |\n",
      "|   model.stage2.layers.0.1.mlp_block.fn.fn.network.0.weight  |   147456   |\n",
      "|    model.stage2.layers.0.1.mlp_block.fn.fn.network.0.bias   |    768     |\n",
      "|   model.stage2.layers.0.1.mlp_block.fn.fn.network.2.weight  |   147456   |\n",
      "|    model.stage2.layers.0.1.mlp_block.fn.fn.network.2.bias   |    192     |\n",
      "|       model.stage3.patch_partition.patch_merge.weight       |   294912   |\n",
      "|        model.stage3.patch_partition.patch_merge.bias        |    384     |\n",
      "|    model.stage3.layers.0.0.attention_block.fn.norm.weight   |    384     |\n",
      "|     model.stage3.layers.0.0.attention_block.fn.norm.bias    |    384     |\n",
      "|    model.stage3.layers.0.0.attention_block.fn.fn.pos_emb    |     9      |\n",
      "|      model.stage3.layers.0.0.attention_block.fn.fn.tau      |     1      |\n",
      "| model.stage3.layers.0.0.attention_block.fn.fn.to_qkv.weight |   442368   |\n",
      "| model.stage3.layers.0.0.attention_block.fn.fn.to_out.weight |   147456   |\n",
      "|  model.stage3.layers.0.0.attention_block.fn.fn.to_out.bias  |    384     |\n",
      "|       model.stage3.layers.0.0.mlp_block.fn.norm.weight      |    384     |\n",
      "|        model.stage3.layers.0.0.mlp_block.fn.norm.bias       |    384     |\n",
      "|   model.stage3.layers.0.0.mlp_block.fn.fn.network.0.weight  |   589824   |\n",
      "|    model.stage3.layers.0.0.mlp_block.fn.fn.network.0.bias   |    1536    |\n",
      "|   model.stage3.layers.0.0.mlp_block.fn.fn.network.2.weight  |   589824   |\n",
      "|    model.stage3.layers.0.0.mlp_block.fn.fn.network.2.bias   |    384     |\n",
      "|    model.stage3.layers.0.1.attention_block.fn.norm.weight   |    384     |\n",
      "|     model.stage3.layers.0.1.attention_block.fn.norm.bias    |    384     |\n",
      "|    model.stage3.layers.0.1.attention_block.fn.fn.pos_emb    |     9      |\n",
      "|      model.stage3.layers.0.1.attention_block.fn.fn.tau      |     1      |\n",
      "| model.stage3.layers.0.1.attention_block.fn.fn.to_qkv.weight |   442368   |\n",
      "| model.stage3.layers.0.1.attention_block.fn.fn.to_out.weight |   147456   |\n",
      "|  model.stage3.layers.0.1.attention_block.fn.fn.to_out.bias  |    384     |\n",
      "|       model.stage3.layers.0.1.mlp_block.fn.norm.weight      |    384     |\n",
      "|        model.stage3.layers.0.1.mlp_block.fn.norm.bias       |    384     |\n",
      "|   model.stage3.layers.0.1.mlp_block.fn.fn.network.0.weight  |   589824   |\n",
      "|    model.stage3.layers.0.1.mlp_block.fn.fn.network.0.bias   |    1536    |\n",
      "|   model.stage3.layers.0.1.mlp_block.fn.fn.network.2.weight  |   589824   |\n",
      "|    model.stage3.layers.0.1.mlp_block.fn.fn.network.2.bias   |    384     |\n",
      "|       model.stage4.patch_partition.patch_merge.weight       |  1179648   |\n",
      "|        model.stage4.patch_partition.patch_merge.bias        |    768     |\n",
      "|    model.stage4.layers.0.0.attention_block.fn.norm.weight   |    768     |\n",
      "|     model.stage4.layers.0.0.attention_block.fn.norm.bias    |    768     |\n",
      "|    model.stage4.layers.0.0.attention_block.fn.fn.pos_emb    |     9      |\n",
      "|      model.stage4.layers.0.0.attention_block.fn.fn.tau      |     1      |\n",
      "| model.stage4.layers.0.0.attention_block.fn.fn.to_qkv.weight |  1769472   |\n",
      "| model.stage4.layers.0.0.attention_block.fn.fn.to_out.weight |   589824   |\n",
      "|  model.stage4.layers.0.0.attention_block.fn.fn.to_out.bias  |    768     |\n",
      "|       model.stage4.layers.0.0.mlp_block.fn.norm.weight      |    768     |\n",
      "|        model.stage4.layers.0.0.mlp_block.fn.norm.bias       |    768     |\n",
      "|   model.stage4.layers.0.0.mlp_block.fn.fn.network.0.weight  |  2359296   |\n",
      "|    model.stage4.layers.0.0.mlp_block.fn.fn.network.0.bias   |    3072    |\n",
      "|   model.stage4.layers.0.0.mlp_block.fn.fn.network.2.weight  |  2359296   |\n",
      "|    model.stage4.layers.0.0.mlp_block.fn.fn.network.2.bias   |    768     |\n",
      "|    model.stage4.layers.0.1.attention_block.fn.norm.weight   |    768     |\n",
      "|     model.stage4.layers.0.1.attention_block.fn.norm.bias    |    768     |\n",
      "|    model.stage4.layers.0.1.attention_block.fn.fn.pos_emb    |     9      |\n",
      "|      model.stage4.layers.0.1.attention_block.fn.fn.tau      |     1      |\n",
      "| model.stage4.layers.0.1.attention_block.fn.fn.to_qkv.weight |  1769472   |\n",
      "| model.stage4.layers.0.1.attention_block.fn.fn.to_out.weight |   589824   |\n",
      "|  model.stage4.layers.0.1.attention_block.fn.fn.to_out.bias  |    768     |\n",
      "|       model.stage4.layers.0.1.mlp_block.fn.norm.weight      |    768     |\n",
      "|        model.stage4.layers.0.1.mlp_block.fn.norm.bias       |    768     |\n",
      "|   model.stage4.layers.0.1.mlp_block.fn.fn.network.0.weight  |  2359296   |\n",
      "|    model.stage4.layers.0.1.mlp_block.fn.fn.network.0.bias   |    3072    |\n",
      "|   model.stage4.layers.0.1.mlp_block.fn.fn.network.2.weight  |  2359296   |\n",
      "|    model.stage4.layers.0.1.mlp_block.fn.fn.network.2.bias   |    768     |\n",
      "+-------------------------------------------------------------+------------+\n",
      "Total Trainable Params: 20383856\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20383856"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from prettytable import PrettyTable\n",
    "\n",
    "def count_parameters(model):\n",
    "    table = PrettyTable([\"Modules\", \"Parameters\"])\n",
    "    total_params = 0\n",
    "    for name, parameter in model.named_parameters():\n",
    "        if not parameter.requires_grad:\n",
    "            continue\n",
    "        params = parameter.numel()\n",
    "        table.add_row([name, params])\n",
    "        total_params += params\n",
    "    print(table)\n",
    "    print(f\"Total Trainable Params: {total_params}\")\n",
    "    return total_params\n",
    "    \n",
    "count_parameters(back_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------------------------------------+------------+\n",
      "|                           Modules                           | Parameters |\n",
      "+-------------------------------------------------------------+------------+\n",
      "|    model.stage1.layers.0.0.attention_block.fn.norm.weight   |    768     |\n",
      "|     model.stage1.layers.0.0.attention_block.fn.norm.bias    |    768     |\n",
      "|    model.stage1.layers.0.0.attention_block.fn.fn.pos_emb    |     9      |\n",
      "|      model.stage1.layers.0.0.attention_block.fn.fn.tau      |     1      |\n",
      "| model.stage1.layers.0.0.attention_block.fn.fn.to_qkv.weight |   221184   |\n",
      "| model.stage1.layers.0.0.attention_block.fn.fn.to_out.weight |   73728    |\n",
      "|  model.stage1.layers.0.0.attention_block.fn.fn.to_out.bias  |    768     |\n",
      "|       model.stage1.layers.0.0.mlp_block.fn.norm.weight      |    768     |\n",
      "|        model.stage1.layers.0.0.mlp_block.fn.norm.bias       |    768     |\n",
      "|   model.stage1.layers.0.0.mlp_block.fn.fn.network.0.weight  |   294912   |\n",
      "|    model.stage1.layers.0.0.mlp_block.fn.fn.network.0.bias   |    384     |\n",
      "|   model.stage1.layers.0.0.mlp_block.fn.fn.network.2.weight  |   294912   |\n",
      "|    model.stage1.layers.0.0.mlp_block.fn.fn.network.2.bias   |    768     |\n",
      "|    model.stage1.layers.0.1.attention_block.fn.norm.weight   |    768     |\n",
      "|     model.stage1.layers.0.1.attention_block.fn.norm.bias    |    768     |\n",
      "|    model.stage1.layers.0.1.attention_block.fn.fn.pos_emb    |     9      |\n",
      "|      model.stage1.layers.0.1.attention_block.fn.fn.tau      |     1      |\n",
      "| model.stage1.layers.0.1.attention_block.fn.fn.to_qkv.weight |   221184   |\n",
      "| model.stage1.layers.0.1.attention_block.fn.fn.to_out.weight |   73728    |\n",
      "|  model.stage1.layers.0.1.attention_block.fn.fn.to_out.bias  |    768     |\n",
      "|       model.stage1.layers.0.1.mlp_block.fn.norm.weight      |    768     |\n",
      "|        model.stage1.layers.0.1.mlp_block.fn.norm.bias       |    768     |\n",
      "|   model.stage1.layers.0.1.mlp_block.fn.fn.network.0.weight  |   294912   |\n",
      "|    model.stage1.layers.0.1.mlp_block.fn.fn.network.0.bias   |    384     |\n",
      "|   model.stage1.layers.0.1.mlp_block.fn.fn.network.2.weight  |   294912   |\n",
      "|    model.stage1.layers.0.1.mlp_block.fn.fn.network.2.bias   |    768     |\n",
      "|    model.stage2.layers.0.0.attention_block.fn.norm.weight   |    384     |\n",
      "|     model.stage2.layers.0.0.attention_block.fn.norm.bias    |    384     |\n",
      "|    model.stage2.layers.0.0.attention_block.fn.fn.pos_emb    |     9      |\n",
      "|      model.stage2.layers.0.0.attention_block.fn.fn.tau      |     1      |\n",
      "| model.stage2.layers.0.0.attention_block.fn.fn.to_qkv.weight |   221184   |\n",
      "| model.stage2.layers.0.0.attention_block.fn.fn.to_out.weight |   73728    |\n",
      "|  model.stage2.layers.0.0.attention_block.fn.fn.to_out.bias  |    384     |\n",
      "|       model.stage2.layers.0.0.mlp_block.fn.norm.weight      |    384     |\n",
      "|        model.stage2.layers.0.0.mlp_block.fn.norm.bias       |    384     |\n",
      "|   model.stage2.layers.0.0.mlp_block.fn.fn.network.0.weight  |   294912   |\n",
      "|    model.stage2.layers.0.0.mlp_block.fn.fn.network.0.bias   |    768     |\n",
      "|   model.stage2.layers.0.0.mlp_block.fn.fn.network.2.weight  |   294912   |\n",
      "|    model.stage2.layers.0.0.mlp_block.fn.fn.network.2.bias   |    384     |\n",
      "|    model.stage2.layers.0.1.attention_block.fn.norm.weight   |    384     |\n",
      "|     model.stage2.layers.0.1.attention_block.fn.norm.bias    |    384     |\n",
      "|    model.stage2.layers.0.1.attention_block.fn.fn.pos_emb    |     9      |\n",
      "|      model.stage2.layers.0.1.attention_block.fn.fn.tau      |     1      |\n",
      "| model.stage2.layers.0.1.attention_block.fn.fn.to_qkv.weight |   221184   |\n",
      "| model.stage2.layers.0.1.attention_block.fn.fn.to_out.weight |   73728    |\n",
      "|  model.stage2.layers.0.1.attention_block.fn.fn.to_out.bias  |    384     |\n",
      "|       model.stage2.layers.0.1.mlp_block.fn.norm.weight      |    384     |\n",
      "|        model.stage2.layers.0.1.mlp_block.fn.norm.bias       |    384     |\n",
      "|   model.stage2.layers.0.1.mlp_block.fn.fn.network.0.weight  |   294912   |\n",
      "|    model.stage2.layers.0.1.mlp_block.fn.fn.network.0.bias   |    768     |\n",
      "|   model.stage2.layers.0.1.mlp_block.fn.fn.network.2.weight  |   294912   |\n",
      "|    model.stage2.layers.0.1.mlp_block.fn.fn.network.2.bias   |    384     |\n",
      "|    model.stage3.layers.0.0.attention_block.fn.norm.weight   |    192     |\n",
      "|     model.stage3.layers.0.0.attention_block.fn.norm.bias    |    192     |\n",
      "|    model.stage3.layers.0.0.attention_block.fn.fn.pos_emb    |     9      |\n",
      "|      model.stage3.layers.0.0.attention_block.fn.fn.tau      |     1      |\n",
      "| model.stage3.layers.0.0.attention_block.fn.fn.to_qkv.weight |   221184   |\n",
      "| model.stage3.layers.0.0.attention_block.fn.fn.to_out.weight |   73728    |\n",
      "|  model.stage3.layers.0.0.attention_block.fn.fn.to_out.bias  |    192     |\n",
      "|       model.stage3.layers.0.0.mlp_block.fn.norm.weight      |    192     |\n",
      "|        model.stage3.layers.0.0.mlp_block.fn.norm.bias       |    192     |\n",
      "|   model.stage3.layers.0.0.mlp_block.fn.fn.network.0.weight  |   294912   |\n",
      "|    model.stage3.layers.0.0.mlp_block.fn.fn.network.0.bias   |    1536    |\n",
      "|   model.stage3.layers.0.0.mlp_block.fn.fn.network.2.weight  |   294912   |\n",
      "|    model.stage3.layers.0.0.mlp_block.fn.fn.network.2.bias   |    192     |\n",
      "|    model.stage3.layers.0.1.attention_block.fn.norm.weight   |    192     |\n",
      "|     model.stage3.layers.0.1.attention_block.fn.norm.bias    |    192     |\n",
      "|    model.stage3.layers.0.1.attention_block.fn.fn.pos_emb    |     9      |\n",
      "|      model.stage3.layers.0.1.attention_block.fn.fn.tau      |     1      |\n",
      "| model.stage3.layers.0.1.attention_block.fn.fn.to_qkv.weight |   221184   |\n",
      "| model.stage3.layers.0.1.attention_block.fn.fn.to_out.weight |   73728    |\n",
      "|  model.stage3.layers.0.1.attention_block.fn.fn.to_out.bias  |    192     |\n",
      "|       model.stage3.layers.0.1.mlp_block.fn.norm.weight      |    192     |\n",
      "|        model.stage3.layers.0.1.mlp_block.fn.norm.bias       |    192     |\n",
      "|   model.stage3.layers.0.1.mlp_block.fn.fn.network.0.weight  |   294912   |\n",
      "|    model.stage3.layers.0.1.mlp_block.fn.fn.network.0.bias   |    1536    |\n",
      "|   model.stage3.layers.0.1.mlp_block.fn.fn.network.2.weight  |   294912   |\n",
      "|    model.stage3.layers.0.1.mlp_block.fn.fn.network.2.bias   |    192     |\n",
      "|    model.stage4.layers.0.0.attention_block.fn.norm.weight   |     96     |\n",
      "|     model.stage4.layers.0.0.attention_block.fn.norm.bias    |     96     |\n",
      "|    model.stage4.layers.0.0.attention_block.fn.fn.pos_emb    |     9      |\n",
      "|      model.stage4.layers.0.0.attention_block.fn.fn.tau      |     1      |\n",
      "| model.stage4.layers.0.0.attention_block.fn.fn.to_qkv.weight |   221184   |\n",
      "| model.stage4.layers.0.0.attention_block.fn.fn.to_out.weight |   73728    |\n",
      "|  model.stage4.layers.0.0.attention_block.fn.fn.to_out.bias  |     96     |\n",
      "|       model.stage4.layers.0.0.mlp_block.fn.norm.weight      |     96     |\n",
      "|        model.stage4.layers.0.0.mlp_block.fn.norm.bias       |     96     |\n",
      "|   model.stage4.layers.0.0.mlp_block.fn.fn.network.0.weight  |   294912   |\n",
      "|    model.stage4.layers.0.0.mlp_block.fn.fn.network.0.bias   |    3072    |\n",
      "|   model.stage4.layers.0.0.mlp_block.fn.fn.network.2.weight  |   294912   |\n",
      "|    model.stage4.layers.0.0.mlp_block.fn.fn.network.2.bias   |     96     |\n",
      "|    model.stage4.layers.0.1.attention_block.fn.norm.weight   |     96     |\n",
      "|     model.stage4.layers.0.1.attention_block.fn.norm.bias    |     96     |\n",
      "|    model.stage4.layers.0.1.attention_block.fn.fn.pos_emb    |     9      |\n",
      "|      model.stage4.layers.0.1.attention_block.fn.fn.tau      |     1      |\n",
      "| model.stage4.layers.0.1.attention_block.fn.fn.to_qkv.weight |   221184   |\n",
      "| model.stage4.layers.0.1.attention_block.fn.fn.to_out.weight |   73728    |\n",
      "|  model.stage4.layers.0.1.attention_block.fn.fn.to_out.bias  |     96     |\n",
      "|       model.stage4.layers.0.1.mlp_block.fn.norm.weight      |     96     |\n",
      "|        model.stage4.layers.0.1.mlp_block.fn.norm.bias       |     96     |\n",
      "|   model.stage4.layers.0.1.mlp_block.fn.fn.network.0.weight  |   294912   |\n",
      "|    model.stage4.layers.0.1.mlp_block.fn.fn.network.0.bias   |    3072    |\n",
      "|   model.stage4.layers.0.1.mlp_block.fn.fn.network.2.weight  |   294912   |\n",
      "|    model.stage4.layers.0.1.mlp_block.fn.fn.network.2.bias   |     96     |\n",
      "+-------------------------------------------------------------+------------+\n",
      "Total Trainable Params: 7106768\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "7106768"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_parameters(neck_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pikachu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
